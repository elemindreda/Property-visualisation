{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import tabula\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import xlsxwriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timesleep(secs):\n",
    "    if secs == 'rand200':\n",
    "        secs = np.random.randint(100,200)\n",
    "    elif secs == 'rand20':\n",
    "        secs = np.random.randint(5,20)\n",
    "    for t in range(0,secs):\n",
    "        time.sleep(1)\n",
    "        print(t+1, end=' -> ')\n",
    "    print('\\n')\n",
    "        \n",
    "def save_data(browser, suburb, property_data):\n",
    "    results = browser.find_elements_by_xpath('//*[@id]')\n",
    "    for ids in results:\n",
    "        if ids.get_attribute('id').startswith('r'):\n",
    "            address = browser.find_element_by_xpath('//*[@id=\"'+ids.get_attribute('id')+'\"]/tbody/tr/td[2]/table/tbody/tr[1]/td/span[2]').text\n",
    "            table_data = browser.find_element_by_xpath('//*[@id=\"'+ids.get_attribute('id')+'\"]/tbody/tr/td[2]/table/tbody/tr[2]/td/table').text\n",
    "            table_data = table_data.split('\\n')\n",
    "            property_data[address+suburb] = table_data\n",
    "#             print('\\n'+ids.get_attribute('id')+' ----> '+address+' ----> '+table_data[0])\n",
    "    return browser, property_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skip_pages(next_button, page):\n",
    "    for row in next_button.find_elements_by_css_selector('td'):\n",
    "        if row.text == str(page):\n",
    "            next_page = row\n",
    "            \n",
    "    return next_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_skip_pages(browser, page):\n",
    "    \n",
    "    print('====== Skipping Pages =====')\n",
    "    timesleep('rand20')\n",
    "    Run = True\n",
    "    current_page = 1\n",
    "    while Run:\n",
    "        next_button = browser.find_element_by_xpath('/html/body/center/table/tbody')\n",
    "        if page > 10 and current_page == 1:\n",
    "            print('====== Skipping to Page 10 =====')\n",
    "            current_page = 10\n",
    "            row = skip_pages(next_button, 10)\n",
    "            row.click()\n",
    "            timesleep('rand20')\n",
    "            if 15 > page > 10:\n",
    "                Run = False\n",
    "        elif page > 15 and current_page == 10:\n",
    "            current_page = 15\n",
    "            row = skip_pages(next_button, 15)\n",
    "            row.click()\n",
    "            timesleep('rand20')\n",
    "            if 20 > page > 15:\n",
    "                Run = False\n",
    "            print('====== Skipping to Page 15 =====')\n",
    "        elif page > 20 and current_page == 15:\n",
    "            current_page = 20\n",
    "            row = skip_pages(next_button, 20)\n",
    "            row.click()\n",
    "            timesleep('rand20')\n",
    "            if 25 > page > 20:\n",
    "                Run = False\n",
    "            print('====== Skipping to Page 20')\n",
    "        elif page > 25 and current_page == 20:\n",
    "            row = skip_pages(next_button, 25)\n",
    "            row.click()\n",
    "            timesleep('rand20')\n",
    "            if 30 > page > 25:\n",
    "                Run = False\n",
    "            print('====== Skipping to Page 25')\n",
    "    return browser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GET_SOLD_DATA(browser, url, suburb, property_data, page):\n",
    "    #Start Searching sold properties\n",
    " \n",
    "    Run = True\n",
    "    browser = check_skip_pages(browser, page)\n",
    "    try:\n",
    "        while Run:\n",
    "            browser, property_data = save_data(browser, suburb, property_data)\n",
    "            timesleep('rand20')\n",
    "            page +=1 #NextPage\n",
    "            next_button = browser.find_element_by_xpath('/html/body/center/table/tbody')\n",
    "            for row in next_button.find_elements_by_css_selector('td'):\n",
    "                if row.text == str(page):\n",
    "                    next_page = row\n",
    "                    Run = True\n",
    "                    break\n",
    "                else:\n",
    "                    Run = False\n",
    "                \n",
    "            print('========================================================= Page Number ---> '+str(page))\n",
    "            next_page.click()\n",
    "            timesleep('rand20')\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print('its failing here')\n",
    "        print('======================> '+suburb + ' ended loop @page # '+str(page))\n",
    "        return property_data, page\n",
    "    print('======================> '+suburb + ' ended loop @page # '+str(page))\n",
    "    return property_data, page\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkupdate(suburb):\n",
    "    print(suburb+' Up To Date')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " DAWES POINT NSW 2000 Up To Date\n",
      " HAYMARKET NSW 2000 Up To Date\n",
      " MILLERS POINT NSW 2000 Up To Date\n",
      " PARLIAMENT HOUSE NSW 2000 Up To Date\n",
      " SYDNEY NSW 2000 Up To Date\n",
      " SYDNEY SOUTH NSW 2000 Up To Date\n",
      " THE ROCKS NSW 2000 Up To Date\n",
      " SYDNEY NSW 2001 Up To Date\n",
      " WORLD SQUARE NSW 2002 Up To Date\n",
      " THE UNIVERSITY OF SYDNEY NSW 2006 Up To Date\n",
      "loading webpage...\n",
      "1 -> 2 -> 3 -> 4 -> 5 -> \n",
      "\n",
      "searching for the  BROADWAY NSW 2007...\n",
      "1 -> 2 -> 3 -> 4 -> 5 -> \n",
      "\n",
      "====== Skipping Pages =====\n",
      "1 -> 2 -> 3 -> 4 -> 5 -> 6 -> 7 -> 8 -> 9 -> 10 -> 11 -> 12 -> 13 -> 14 -> 15 -> 16 -> 17 -> 18 -> \n",
      "\n",
      "====== Skipping to Page 10 =====\n",
      "1 -> 2 -> 3 -> 4 -> 5 -> 6 -> 7 -> 8 -> 9 -> 10 -> \n",
      "\n",
      "1 -> 2 -> 3 -> 4 -> 5 -> 6 -> 7 -> 8 -> 9 -> 10 -> 11 -> 12 -> \n",
      "\n",
      "====== Skipping to Page 15 =====\n",
      "1 -> 2 -> 3 -> 4 -> 5 -> 6 -> 7 -> 8 -> 9 -> 10 -> 11 -> 12 -> \n",
      "\n",
      "====== Skipping to Page 20\n",
      "1 -> 2 -> 3 -> 4 -> 5 -> 6 -> 7 -> 8 -> 9 -> 10 -> 11 -> 12 -> \n",
      "\n",
      "========================================================= Page Number ---> 23\n",
      "1 -> 2 -> 3 -> 4 -> 5 -> \n",
      "\n",
      "1 -> 2 -> 3 -> 4 -> 5 -> 6 -> 7 -> 8 -> 9 -> 10 -> 11 -> 12 -> 13 -> 14 -> 15 -> 16 -> 17 -> 18 -> \n",
      "\n",
      "========================================================= Page Number ---> 24\n",
      "1 -> 2 -> 3 -> 4 -> 5 -> 6 -> 7 -> 8 -> 9 -> 10 -> 11 -> 12 -> 13 -> \n",
      "\n",
      "1 -> 2 -> 3 -> 4 -> 5 -> 6 -> 7 -> 8 -> 9 -> 10 -> 11 -> 12 -> 13 -> \n",
      "\n",
      "========================================================= Page Number ---> 25\n",
      "1 -> 2 -> 3 -> 4 -> 5 -> 6 -> 7 -> 8 -> 9 -> 10 -> 11 -> 12 -> 13 -> 14 -> 15 -> 16 -> 17 -> 18 -> \n",
      "\n",
      "1 -> 2 -> 3 -> 4 -> 5 -> 6 -> 7 -> 8 -> 9 -> 10 -> 11 -> \n",
      "\n",
      "========================================================= Page Number ---> 26\n",
      "1 -> 2 -> 3 -> 4 -> 5 -> 6 -> 7 -> 8 -> 9 -> 10 -> 11 -> 12 -> 13 -> \n",
      "\n",
      "1 -> 2 -> 3 -> 4 -> 5 -> 6 -> 7 -> 8 -> \n",
      "\n",
      "========================================================= Page Number ---> 27\n",
      "1 -> 2 -> 3 -> 4 -> 5 -> \n",
      "\n",
      "1 -> 2 -> 3 -> 4 -> 5 -> 6 -> 7 -> 8 -> 9 -> 10 -> 11 -> \n",
      "\n",
      "========================================================= Page Number ---> 28\n",
      "1 -> 2 -> 3 -> 4 -> 5 -> 6 -> 7 -> 8 -> 9 -> 10 -> 11 -> 12 -> 13 -> 14 -> 15 -> 16 -> \n",
      "\n",
      "1 -> 2 -> 3 -> 4 -> 5 -> 6 -> 7 -> 8 -> 9 -> 10 -> 11 -> 12 -> 13 -> 14 -> 15 -> 16 -> 17 -> 18 -> \n",
      "\n",
      "========================================================= Page Number ---> 29\n",
      "1 -> 2 -> 3 -> 4 -> 5 -> 6 -> 7 -> 8 -> 9 -> 10 -> 11 -> 12 -> 13 -> 14 -> 15 -> 16 -> 17 -> \n",
      "\n",
      "1 -> 2 -> 3 -> 4 -> 5 -> 6 -> 7 -> 8 -> \n",
      "\n",
      "========================================================= Page Number ---> 30\n",
      "1 -> 2 -> 3 -> 4 -> 5 -> 6 -> 7 -> 8 -> 9 -> 10 -> 11 -> 12 -> 13 -> 14 -> \n",
      "\n",
      "1 -> 2 -> 3 -> 4 -> 5 -> 6 -> 7 -> 8 -> 9 -> 10 -> 11 -> 12 -> 13 -> 14 -> 15 -> \n",
      "\n",
      "========================================================= Page Number ---> 31\n",
      "Message: Web element reference not seen before: 751fae2b-e2ff-48d5-bf76-6f2ecc9b3134\n",
      "\n",
      "its failing here\n",
      "======================>  BROADWAY NSW 2007 ended loop @page_number 31\n",
      "1 -> 2 -> 3 -> 4 -> 5 -> 6 -> 7 -> 8 -> 9 -> 10 -> 11 -> 12 -> 13 -> 14 -> 15 -> 16 -> 17 -> 18 -> 19 -> 20 -> 21 -> 22 -> 23 -> 24 -> 25 -> 26 -> 27 -> 28 -> 29 -> 30 -> 31 -> 32 -> 33 -> 34 -> 35 -> 36 -> 37 -> 38 -> 39 -> 40 -> 41 -> 42 -> 43 -> 44 -> 45 -> 46 -> 47 -> 48 -> 49 -> 50 -> 51 -> 52 -> "
     ]
    }
   ],
   "source": [
    "# def main():\n",
    "property_data = {}\n",
    "postcodes = pd.read_csv('postcode.csv', index_col = 0)\n",
    "url = 'http://house.ksou.cn/index.php'\n",
    "log = []\n",
    "for suburb, page in postcodes.values.tolist():\n",
    "    if page >= 31:\n",
    "        checkupdate(suburb) \n",
    "    else:\n",
    "        try:\n",
    "            browser = webdriver.Firefox()\n",
    "            print('loading webpage...')\n",
    "            browser.get(url)\n",
    "            timesleep(5)\n",
    "\n",
    "            inputElement = browser.find_element_by_id('q')\n",
    "            button = browser.find_element_by_xpath('/html/body/center/form/table/tbody/tr/td[2]/input')\n",
    "            inputElement.send_keys(suburb)\n",
    "            print('searching for the '+suburb+'...')\n",
    "            button.click()\n",
    "            timesleep(5)\n",
    "            main_window = browser.current_window_handle\n",
    "\n",
    "            property_data, log = GET_SOLD_DATA(browser, url, suburb, property_data, page)\n",
    "            browser.quit()\n",
    "\n",
    "            property_df = pd.DataFrame.from_dict(property_data, orient='index')\n",
    "            property_df.to_csv('property_data.csv')\n",
    "            postcodes.loc[(postcodes.suburb == suburb),'page'] = log\n",
    "            postcodes.to_csv('postcode.csv')\n",
    "            timesleep('rand200')\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(suburb+' failed at '+str(page))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
